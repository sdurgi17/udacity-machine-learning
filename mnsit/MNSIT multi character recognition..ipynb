{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA\n",
    "----\n",
    "The data is found in the data directory.\n",
    "It has two files train-images-idx3-ubyte (for image data) and train-images-idx3-ubyte (for labels)\n",
    "The data needs some processing to be displayed as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load all dependencies\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loosely inspired by http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "which is GPL licensed.\n",
    "\"\"\"\n",
    "\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError, \"dataset must be 'testing' or 'training'\"\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in xrange(len(lbl)):\n",
    "        yield get_img(i)\n",
    "\n",
    "def show(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "3\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSOj/Ac57xUmjPoT+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed4715b610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#show a random image\n",
    "%matplotlib inline\n",
    "training_data = list(read('training', './data'))\n",
    "testing_data = list(read('training', './data'))\n",
    "print(len(training_data))\n",
    "label, pixels = training_data[random.randint(0,len(training_data))]\n",
    "print (label)\n",
    "print (pixels.shape)\n",
    "show(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a new dataset which has multiple characters(2-5). Each generated image will be of 5x length(blank images are stitched where number of characters is less than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]\n",
      "[8, 7]\n"
     ]
    }
   ],
   "source": [
    "def generateAMultiCharImage(length = -1):\n",
    "    if length == -1:\n",
    "        length = random.randint(2,5)\n",
    "    final_label = []\n",
    "    final_pixels = np.zeros((28, 5 * 28))\n",
    "    for i in xrange(length):\n",
    "        label, pixels = training_data[random.randint(0,len(training_data) - 1)]\n",
    "        final_pixels[:, i*28:(i+1)*28] = pixels\n",
    "        final_label.append(label)\n",
    "    final_pixels = np.reshape(final_pixels, (28, 28 * 5, 1))\n",
    "    label_one_hot = []\n",
    "    label_one_hot.append([0] * 6)\n",
    "    print(len(label_one_hot))\n",
    "    label_one_hot[0][len(final_label)] = 1\n",
    "    i = 1\n",
    "    for num in final_label:\n",
    "        label_one_hot.append([0] * 10)\n",
    "        label_one_hot[i][final_label[i - 1]] = 1\n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    return {\"image\" : final_pixels, \"label\" : label_one_hot, \"num_arr\" : final_label }\n",
    "\n",
    "def getBatchData(size = 100):\n",
    "    batch = {\"data\" : [], \"labels\" : []}\n",
    "    for i in xrange(100):\n",
    "        data = generateAMultiCharImage()\n",
    "        batch[\"data\"].append(data[\"image\"])\n",
    "        label = [0] * 10\n",
    "        label[data[\"label\"][0]] = 1\n",
    "        batch[\"labels\"].append(label)\n",
    "    return batch\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "        \n",
    "# a = getBatchData()\n",
    "a = generateAMultiCharImage()\n",
    "print(a[\"label\"])\n",
    "print(a[\"num_arr\"])\n",
    "# print(len(a[\"data\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 100\n",
    "image_height = 28\n",
    "image_width = 5 * 28\n",
    "num_channels = 1\n",
    "num_labels = 10\n",
    "graph = tf.Graph()\n",
    "valid_data = getBatchData(500)\n",
    "valid_dataset = np.array(valid_data[\"data\"], dtype=np.float32)\n",
    "valid_labels = np.array(valid_data[\"labels\"], dtype=np.float32)\n",
    "\n",
    "test_data = getBatchData(500)\n",
    "test_dataset = np.array(test_data[\"data\"], dtype=np.float32)\n",
    "test_labels = np.array(test_data[\"labels\"], dtype=np.float32)\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_height, image_width, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_height // 4 * image_width // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    after_max_pool_1 = tf.nn.max_pool(hidden, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "    conv = tf.nn.conv2d(after_max_pool_1, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    after_max_pool_2 = tf.nn.max_pool(hidden, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "    shape = after_max_pool_2.get_shape().as_list()\n",
    "    reshape = tf.reshape(after_max_pool_2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "[  1.82536586e-29   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 0: 289.575867\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 12.0%\n",
      "[ 0.07146059  0.1149429   0.05076832  0.01476169  0.30117899  0.05261385\n",
      "  0.17597687  0.04895129  0.06980719  0.09953839]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "Minibatch loss at step 50: 2.569883\n",
      "Minibatch accuracy: 10.0%\n",
      "Validation accuracy: 18.0%\n",
      "[ 0.03774406  0.11738942  0.00376146  0.00889116  0.37869039  0.0026386\n",
      "  0.00236103  0.03876303  0.39229757  0.01746329]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 100: 2.197364\n",
      "Minibatch accuracy: 18.0%\n",
      "Validation accuracy: 19.0%\n",
      "[ 0.08222095  0.05045635  0.07668228  0.0967178   0.08562696  0.09750345\n",
      "  0.31848747  0.07102865  0.06741363  0.05386246]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 150: 2.203827\n",
      "Minibatch accuracy: 24.0%\n",
      "Validation accuracy: 23.0%\n",
      "[ 0.07112442  0.18862432  0.14956459  0.04441978  0.04179457  0.09330721\n",
      "  0.0487643   0.17980255  0.11780659  0.06479168]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "Minibatch loss at step 200: 2.260394\n",
      "Minibatch accuracy: 18.0%\n",
      "Validation accuracy: 27.0%\n",
      "[ 0.03402437  0.09776046  0.08043994  0.1328232   0.17643812  0.13054648\n",
      "  0.02980076  0.14988662  0.08518761  0.08309236]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 250: 2.213350\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 28.0%\n",
      "[ 0.10770664  0.13994864  0.07037663  0.08154173  0.03382083  0.08185295\n",
      "  0.28085807  0.09376804  0.05242378  0.05770268]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "Minibatch loss at step 300: 1.981937\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 30.0%\n",
      "[ 0.06596993  0.02004257  0.07365571  0.04426091  0.04862533  0.46928069\n",
      "  0.02229244  0.09902931  0.05472232  0.10212083]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "Minibatch loss at step 350: 2.058581\n",
      "Minibatch accuracy: 23.0%\n",
      "Validation accuracy: 26.0%\n",
      "[ 0.09736265  0.05890671  0.07573282  0.08997188  0.04356709  0.10584188\n",
      "  0.06402449  0.09201013  0.18952134  0.18306099]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "Minibatch loss at step 400: 1.929021\n",
      "Minibatch accuracy: 37.0%\n",
      "Validation accuracy: 31.0%\n",
      "[ 0.05685184  0.51187134  0.02890928  0.01611792  0.10060478  0.04141152\n",
      "  0.03941558  0.09807637  0.08253048  0.02421094]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 450: 1.983478\n",
      "Minibatch accuracy: 33.0%\n",
      "Validation accuracy: 33.0%\n",
      "[ 0.01139079  0.1774375   0.05517261  0.00854511  0.19982576  0.07056547\n",
      "  0.03330563  0.11969642  0.26501638  0.0590444 ]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 500: 2.025155\n",
      "Minibatch accuracy: 27.0%\n",
      "Validation accuracy: 36.0%\n",
      "[ 0.02229284  0.25306749  0.12132387  0.01841486  0.15669751  0.0792108\n",
      "  0.04948277  0.06071086  0.14032885  0.09847023]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 550: 1.816976\n",
      "Minibatch accuracy: 36.0%\n",
      "Validation accuracy: 40.0%\n",
      "[ 0.16070019  0.01198522  0.06977694  0.36908227  0.05782955  0.05622059\n",
      "  0.02663513  0.06639157  0.09671985  0.08465867]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 600: 1.834764\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 41.0%\n",
      "[ 0.050825    0.02723986  0.03464242  0.01607718  0.02632714  0.02312694\n",
      "  0.80129826  0.00984199  0.0069971   0.00362411]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "Minibatch loss at step 650: 1.805078\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 35.0%\n",
      "[ 0.07386231  0.06069758  0.12896588  0.0980568   0.17021649  0.15127903\n",
      "  0.05681901  0.04618968  0.14997092  0.06394235]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 700: 1.785246\n",
      "Minibatch accuracy: 41.0%\n",
      "Validation accuracy: 43.0%\n",
      "[ 0.13916728  0.00983415  0.01103069  0.0257297   0.17367817  0.18311855\n",
      "  0.06832687  0.01675614  0.06052412  0.31183431]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 750: 1.776431\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 39.0%\n",
      "[ 0.01034187  0.11060128  0.2346043   0.00612021  0.04909204  0.06213139\n",
      "  0.00226426  0.26403415  0.25437093  0.00643955]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 800: 1.663309\n",
      "Minibatch accuracy: 39.0%\n",
      "Validation accuracy: 38.0%\n",
      "[ 0.0401261   0.00916081  0.04317578  0.12851021  0.01295903  0.08612444\n",
      "  0.01647348  0.33584931  0.08908396  0.23853686]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "Minibatch loss at step 850: 1.748350\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 41.0%\n",
      "[ 0.1838959   0.01216274  0.0100195   0.08427607  0.01259016  0.17826726\n",
      "  0.00669685  0.31115916  0.06098062  0.13995174]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "Minibatch loss at step 900: 1.416880\n",
      "Minibatch accuracy: 51.0%\n",
      "Validation accuracy: 46.0%\n",
      "[ 0.09306018  0.04199871  0.22946674  0.07568792  0.06533851  0.06383792\n",
      "  0.27226153  0.05470259  0.08171346  0.02193245]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "Minibatch loss at step 950: 1.370682\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 46.0%\n",
      "[ 0.0336568   0.40977016  0.01006879  0.01066667  0.10341913  0.07590227\n",
      "  0.03176184  0.10141304  0.18273149  0.04060983]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Minibatch loss at step 1000: 1.536531\n",
      "Minibatch accuracy: 45.0%\n",
      "Validation accuracy: 49.0%\n",
      "Test accuracy: 44.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    batch = getBatchData() \n",
    "    batch_data = np.array(batch[\"data\"], dtype=np.float32)\n",
    "    batch_labels = np.array(batch[\"labels\"], dtype=np.float32)\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 50 == 0):\n",
    "      print(predictions[0])\n",
    "      print(batch_labels[0])\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
